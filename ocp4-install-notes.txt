
1 x bootstrap
4 cpu 16 GB 120GB

3 x control planes

3 x workers

=======
Infra
=======
static ips or DHCP

bind dns - domains - can be local fictious
A Records
api
api-int
bootstrap
master0
etcd-0
master1
etcd-1
master2
etcd-2
worker0
worker1
worker2
apps (wildcard)
*

NO ETCD Reverse PTR Records only Master and Others

SRV Records
_etcd-server-ssl._tcp   etcd-0.<domain name>
_etcd-server-ssl._tcp   etcd-1.<domain name>
_etcd-server-ssl._tcp   etcd-2.<domain name>


===
Services VM aka Helper Node
===
1. Choose Centos 8, Centos 8 Stream, RHEL 8 and download the chosen ISO
2. Build the VM in vSphere as a 4 CPU, 8GB RAM, 100GB Disk with Static IP address on Main Network
3. Add 2nd NIC to the OCP Network (Non-routable to internet aka NAT Adapter)
4. Start the OS Install - Minimal install, Basic User that is an Admin, Set User and Root Passwords
5. SSH Login to Services VM as local Admin and switch to root - ssh user@services
6. Update the Package Index - yum update -y
7. Set the EPEL Repo - yum -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-$(rpm -E %rhel).noarch.rpm
8. Install vim, ansible and git and clone the Helper Node Repo
    - yum -y install vim ansible git
    - git clone https://github.com/redhat-cop/ocp4-helpernode
9. Clone Ryan Hay's Repo - git clone https://github.com/ryanhay/ocp4-metal-install
10. Update VIM Editor
    cat <<EOT >> ~/.vimrc
    syntax on                                                                                        
    set nu et ai sts=0 ts=2 sw=2 list hls
    EOT
11. Update the 2nd Network Card to be the Internal NAT IP
    - Change the name to ens224
    - Set IP to 192.168.22.1
    - Leave Gateway blank
    - Set DNS to 127.0.0.1
    - Search Search Domain to ocp4.example.com
    - Never use this network for default route
    - Require IPv4 addressing
    - Disable IPv6
    - Automatically Connect
    - Reset 2nd NIC - nmcli connection down ens224, nmcli connection up ens224
12. Setup Firewall Internal Zone
    - nmcli connection modify ens224 connection.zone internal
13. Setup Firewall External Zone
    - nmcli connection modify ens192 connection.zone external
14. Check your Firewall Active Zones
    - firewall-cmd --get-active-zones 
15. Setup Masquerading on the Network Interfaces
    - firewall-cmd --zone=external --add-masquerade --permanent
    - firewall-cmd --zone=internal --add-masquerade --permanent
16. Reload Firewall Config
    - firewall-cmd --reload
17. Verify the Firewall Settings in each Zone
    - firewall-cmd --list-all --zone=internal
    - firewall-cmd --list-all --zone=external
18. Verify IP Forwarding is turned on
    - cat /proc/sys/net/ipv4/ip_forward
19. Copy the /docs/examples/vars.yaml from ocp4-helpernode
    - cd ocp4-helpernode
    - cp docs/examples/vars.yaml .
20. Update the following in the vars.yaml using VIM
    - name
    - ipaddr - NIC #1 IP
    - networkifacename - name of NIC #1
    - domain
    - clusterid
    - forwarder1 - dns upstream
    - forwarder2 - dns upstream
    - router - NIC #2 IP
    - bcast
    - netmask
    - poolstart
    - poolend
    - ipid
    - netmaskid
    - bootstrap ipaddr
    - master0-2 ipaddr
    - worker0-2 ipaddr
    - non-cluster-vm ipaddr
21. Update the following in the vars/main.yaml using VIM
    - force_ocp_download
    - remove_old_config_files
    - ocp_bios - Get Versions here https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos
    - ocp_initramfs - Get Versions here https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos
    - ocp_install_kernel - Get Versions here https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos
    - ocp_client - Get Versions here https://mirror.openshift.com/pub/openshift-v4/clients/ocp
    - ocp_installer - Get Versions here https://mirror.openshift.com/pub/openshift-v4/clients/ocp
    - helm_source - Get Versions here https://github.com/helm/helm/releases
    - uefi
    - setup_registry
        deploy
        autosync_registry
        release_tag
22. Add the PXE section to the vars/main.yaml using VIM
    - After uefi add the line
    pxe:
      generate_default: true
23. Install the python requests module
    - python3 -m pip install requests
#24. Install the Ansible Galaxy Community cryptography module
    - ansible-galaxy collection install community.crypto
#25. Add the following line to the ansible.cfg
    - interpreter_python=/bin/python3
26. Create the OpenShift Pull Secret location
    - mkdir ~/.openshift
27. Download OpenShift Pull Secret
    - Visit try.openshift.com and choose "Bare Metal"
    - Download the pull secret
    - Copy the Pull Secret to ~/.openshift as pull-secret
28. Run the Helper Node Ansible Playbook
    - ansible-playbook -e @vars.yaml tasks/main.yml
29. Update the Firewall Ports
    firewall-cmd --add-port=67/tcp --zone=internal --permanent
    firewall-cmd --add-port=53/tcp --zone=internal --permanent
    firewall-cmd --add-port=53/udp --zone=internal --permanent
    firewall-cmd --add-port=8080/tcp --zone=internal --permanent
    firewall-cmd --add-port=69/udp --zone=internal --permanent
    firewall-cmd --add-port=111/tcp --zone=internal --permanent
    firewall-cmd --add-port=2049/tcp --zone=internal --permanent
    firewall-cmd --add-port=20048/tcp --zone=internal --permanent
    firewall-cmd --add-port=50825/tcp --zone=internal --permanent
    firewall-cmd --add-port=53248/tcp --zone=internal --permanent

    firewall-cmd --add-port=6443/tcp --zone=internal --permanent # kube-api-server on control plane nodes
    firewall-cmd --add-port=6443/tcp --zone=external --permanent # kube-api-server on control plane nodes
    firewall-cmd --add-port=6443/udp --zone=internal --permanent # kube-api-server on control plane nodes
    firewall-cmd --add-port=6443/udp --zone=external --permanent # kube-api-server on control plane nodes

    firewall-cmd --add-port=22623/tcp --zone=internal --permanent # machine-config server
    firewall-cmd --add-port=22623/udp --zone=internal --permanent # machine-config server

    firewall-cmd --add-service=http --zone=internal --permanent # web services hosted on worker nodes
    firewall-cmd --add-service=http --zone=external --permanent # web services hosted on worker nodes
    
    firewall-cmd --add-service=https --zone=internal --permanent # web services hosted on worker nodes
    firewall-cmd --add-service=https --zone=external --permanent # web services hosted on worker nodes
    
    firewall-cmd --add-port=9000/tcp --zone=external --permanent # HAProxy Stats
    
    firewall-cmd --zone=internal --add-service mountd --permanent
    firewall-cmd --zone=internal --add-service rpc-bind --permanent
    firewall-cmd --zone=internal --add-service nfs --permanent

    firewall-cmd --reload

30. Verify Helpernode by running /usr/local/bin/helpernodecheck

31. Verify the SSH Keys in ~/.ssh/helper_rsa
32. Create ocp4 directory
    - mkdir ~/ocp4
    - cd ~/ocp4
33. Create the install-config.yaml in ~/ocp4
cat <<EOF > install-config.yaml
apiVersion: v1
baseDomain: example.com
compute:
- hyperthreading: Enabled
  name: worker
  replicas: 0
controlPlane:
  hyperthreading: Enabled
  name: master
  replicas: 3
metadata:
  name: ocp4
networking:
  clusterNetworks:
  - cidr: 10.128.0.0/14
    hostPrefix: 23
  networkType: OVNKubernetes
  serviceNetwork:
  - 172.30.0.0/16
platform:
  none: {}
pullSecret: '$(< ~/.openshift/pull-secret)'
sshKey: '$(< ~/.ssh/helper_rsa.pub)'
EOF

34. Make a Backup Copy of the install-config.yaml
    - cp install-config.yaml install-config.yaml.orig
35. Create OpenShift Install Manifests
    - openshift-install create manifests
36. Update manifests/cluster-scheduler-02-config.yml
    - set the mastersSchedulable to false
    sed -i 's/mastersSchedulable: true/mastersSchedulable: false/g' manifests/cluster-scheduler-02-config.yml
37. Create a Backup of the manifests and openshift directory
    - mkdir Backup
    - cp -R manifests Backup/
    - cp -R openshift Backup/
38. Create the Ignition Configs
    - openshift-install create ignition-configs
39. Copy the Ignition Configs to the WebServer
    - cp -f ~/ocp4/*.ign /var/www/html/ignition/
    - restorecon -vR /var/www/html/
    - chmod o+r /var/www/html/ignition/*.ign
40. Clone the OCP v4 vSPhere UPI Automation Repo
    - cd ~
    - git clone https://github.com/RedHatOfficial/ocp4-vsphere-upi-automation.git
41. Update the group_vars/all.yml file in the following sections
    - helper_vm_ip -use the internal ip not external ip for 2 nic setup
    - base_domain
    - cluster_name
    - networkType -uncomment and add OpenShiftSDN
    - isolationMode -uncomment and add NetworkPolicy
    - installer_ssh_key -update name of ssh key
    - pull_secret -update name of the pull secret
    - vcenter section ip, datastore, network, usernames, passwords, datacenter, folder path, template_name, hw_version
        clients_url, dependencies_url, govc
    - vms - update mac address and ip address, cpu, ram 
    - static ip
    - proxy
    - registry 
42. Run the Installation Playbook
    - NO ansible-playbook -i staging dhcp_pxe.yml
    -ansible-playbook -i staging dhcp_ova.yml
43. Install the Python Requests module
    - /usr/libexec/platform-python -m pip install requests
44. Check the Bootstrap Installation Status
    ssh -i ~/.ssh/ocp4 core@bootstrap.ocp4.example.com
    journalctl -b -f -u release-image.service -u bootkube.service
45. Check the Other Servers by logging in
    ssh -i ~/.ssh/ocp4 core@master0.ocp4.example.com
46. Check the installation status by logging in via the command line 
    export KUBECONFIG=$(pwd)/install-dir/auth/kubeconfig
    # OpenShift Client Commands
    oc whoami
    oc get nodes
    oc get co
    oc get csr

############################################################
POST OpenShift Installation Tasks
############################################################    
#NFS Server steps - use root
49. Create the NFS Directory for the Image Registry PV
mkdir -p /exports/registry
chown -R nobody:nobody /exports/registry
chmod -R 775 /exports/registry
echo "/exports/registry  192.168.2.0/23(rw,sync,root_squash,no_subtree_check,no_wdelay)" >> /etc/exports
exportfs -rv

50. Create the NFS Directory Share for PVs
mkdir -p /exports/share
chown -R nobody:nobody /exports/share
chmod -R 775 /exports/share
echo "/exports/share  192.168.2.0/23(rw,sync,root_squash,no_subtree_check,no_wdelay)" >> /etc/exports
exportfs -rv

51. Set the SELinux to be persistent across reboots for pods to write to NFS shares
setsebool -P virt_use_nfs 1

52. Set the SElinux settings for NFS directory Read and Write as well as content switch
setsebool -P nfs_export_all_rw 1
setsebool -P nfs_export_all_ro 1

semanage fcontext -a -t public_content_rw_t  "/exports/helper(/.*)?"
restorecon -R /exports/helper

semanage fcontext -a -t public_content_rw_t  "/exports/registry(/.*)?"
restorecon -R /exports/registry

semanage fcontext -a -t public_content_rw_t  "/exports/share(/.*)?"
restorecon -R /exports/share

exportfs -arv

#End NFS Server steps

#LB Server steps

#Setup NFS Storage Provisioner for openshift-image-registry on Cluster using LB/Bastion - need helm 3 installed
#helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner

#helm install -n nfs-provisioning --create-namespace nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner --set nfs.server=192.168.2.25 --set nfs.path=/exports/registry
# Namespace already created so removed the parameter
#helm install -n openshift-image-registry nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner --set nfs.server=192.168.2.25 --set nfs.path=/exports/registry

53. Create openshift-nfs-storage namespace and have the cluster monitor the NFS storage Operator

oc login to openshift 
oc create namespace openshift-nfs-storage
oc label namespace openshift-nfs-storage "openshift.io/cluster-monitoring=true"
oc project openshift-nfs-storage

54. Clone the NFS-Subdir-External provisioner
git clone https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner.git
cd nfs-subdir-external-provisioner

55. Update the RBAC and Deployment YAMLs with the openshift-nfs-storage namespace

NAMESPACE=`oc project -q`
sed -i'' "s/namespace:.*/namespace: $NAMESPACE/g" ./deploy/rbac.yaml ./deploy/deployment.yaml

56. Apply the RBAC YAML and setup the service account
oc create -f deploy/rbac.yaml
oc adm policy add-scc-to-user hostmount-anyuid system:serviceaccount:$NAMESPACE:nfs-client-provisioner

57. Create an NFS Provisioner Deployment for OpenShift Registry
cp deploy/deployment.yaml deploy/deployment-registry.yaml

#Using sed | delimitter instead of / 
NFSCLIENTNAME=nfs-client-provisioner-registry
sed -i'' "s|name: nfs-client-provisioner|name: $NFSCLIENTNAME|g" ./deploy/deployment-registry.yaml
sed -i'' "s|app: nfs-client-provisioner|app: $NFSCLIENTNAME|g" ./deploy/deployment-registry.yaml

#Using sed | delimtter instead of /
STORAGECLASS=registry-nfs-storage
sed -i'' "s|value: k8s-sigs.io/nfs-subdir-external-provisioner|value: k8s-sigs.io/$STORAGECLASS|g" ./deploy/deployment-registry.yaml

#Using sed | delimitter instead of / 
NFSSERVER=ocpnfs.example.com
sed -i'' "s|value: 10.3.243.101|value: $NFSSERVER|g" ./deploy/deployment-registry.yaml
sed -i'' "s|server: 10.3.243.101|server: $NFSSERVER|g" ./deploy/deployment-registry.yaml

#Using sed | delimitter instead of / 
NFSPATH=/exports/registry
sed -i'' "s|value: /ifs/kubernetes|value: $NFSPATH|g" ./deploy/deployment-registry.yaml
sed -i'' "s|path: /ifs/kubernetes|path: $NFSPATH|g" ./deploy/deployment-registry.yaml

58. Create a Storage Class for Registry
echo 'apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: registry-nfs-storage
provisioner: k8s-sigs.io/registry-nfs-storage
parameters:
  pathPattern: "${.PVC.namespace}/${.PVC.name}"
  onDelete: delete
  archiveOnDelete: "false"' > deploy/storageclass-registry.yaml

59. Deploy the NFS Provisioner Deployment for OpenShift Registry and Registry Storage Class
oc create -f deploy/deployment-registry.yaml -f deploy/storageclass-registry.yaml

60. Test the NFS Provisioner with Registry
cp deploy/test-claim.yaml deploy/test-claim-registry.yaml
cp deploy/test-pod.yaml deploy/test-pod-registry.yaml

sed -i'' "s|name: test-claim|name: test-claim-registry|g" ./deploy/test-claim-registry.yaml
sed -i'' "s|storageClassName: nfs-client|storageClassName: registry-nfs-storage|g" ./deploy/test-claim-registry.yaml

sed -i'' "s|name: test-pod|name: test-pod-registry|g" ./deploy/test-pod-registry.yaml
sed -i'' "s|name: nfs-pvc|name: test-nfs-pvc-registry|g" ./deploy/test-pod-registry.yaml
sed -i'' "s|claimName: test-claim|claimName: test-claim-registry|g" ./deploy/test-pod-registry.yaml

oc create -f deploy/test-claim-registry.yaml -f deploy/test-pod-registry.yaml
Verify
oc delete -f deploy/test-claim-registry.yaml -f deploy/test-pod-registry.yaml


61. Set the Image Registry to Managed
    oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"managementState":"Managed"}}'
    #oc patch configs.imageregistry.operator.openshift.io cluster --type merge --patch '{"spec":{"managementState":"Removed"}}'
    oc patch config.imageregistry.operator.openshift.io/cluster --type=merge -p '{"spec":{"rolloutStrategy":"Recreate","replicas":1}}'

62. Create the PVC for the Image Registry
cd ..
oc project openshift-image-registry

echo 'apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: image-registry-storage
  namespace: openshift-image-registry
spec:
  storageClassName: registry-nfs-storage
  accessModes:
    - ReadWriteMany
  resources:
    requests:
        storage: 100Gi' > imageregistry-pvc.yaml

oc create -f imageregistry-pvc.yaml

63. Setup the PVC for the Image Registry
    oc edit configs.imageregistry.operator.openshift.io
    storage:
      pvc:
        claim: image-registry-storage
64. Check the PVC for the Image Registry Status
    oc get pvc -n openshift-image-registry

65.  Create an NFS Provisioner Deployment for OpenShift Storage - General Use
cd nfs-subdir-external-provisioner
cp deploy/deployment.yaml deploy/deployment-managed.yaml

#Using sed | delimitter instead of / 
NFSCLIENTNAME=nfs-client-provisioner-managed
sed -i'' "s|name: nfs-client-provisioner|name: $NFSCLIENTNAME|g" ./deploy/deployment-managed.yaml
sed -i'' "s|app: nfs-client-provisioner|app: $NFSCLIENTNAME|g" ./deploy/deployment-managed.yaml

#Using sed | delimtter instead of /
STORAGECLASS=managed-nfs-storage
sed -i'' "s|value: k8s-sigs.io/nfs-subdir-external-provisioner|value: k8s-sigs.io/$STORAGECLASS|g" ./deploy/deployment-managed.yaml

#Using sed | delimitter instead of / 
NFSSERVER=ocpnfs.example.com
sed -i'' "s|value: 10.3.243.101|value: $NFSSERVER|g" ./deploy/deployment-managed.yaml
sed -i'' "s|server: 10.3.243.101|server: $NFSSERVER|g" ./deploy/deployment-managed.yaml

#Using sed | delimitter instead of / 
NFSPATH=/exports/share
sed -i'' "s|value: /ifs/kubernetes|value: $NFSPATH|g" ./deploy/deployment-managed.yaml
sed -i'' "s|path: /ifs/kubernetes|path: $NFSPATH|g" ./deploy/deployment-managed.yaml

66. Create a Storage Class for OpenShift Storage - General Use
echo 'apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: managed-nfs-storage
provisioner: k8s-sigs.io/managed-nfs-storage
parameters:
  pathPattern: "${.PVC.namespace}/${.PVC.name}"
  onDelete: delete
  archiveOnDelete: "false"' > deploy/storageclass-managed.yaml

67. Deploy the NFS Provisioner Deployment for OpenShift Managed and Managed Storage Class
oc project openshift-nfs-storage
oc create -f deploy/deployment-managed.yaml -f deploy/storageclass-managed.yaml

68. Test the NFS Provisioner with Registry
cp deploy/test-claim.yaml deploy/test-claim-managed.yaml
cp deploy/test-pod.yaml deploy/test-pod-managed.yaml

sed -i'' "s|name: test-claim|name: test-claim-managed|g" ./deploy/test-claim-managed.yaml
sed -i'' "s|storageClassName: nfs-client|storageClassName: managed-nfs-storage|g" ./deploy/test-claim-managed.yaml

sed -i'' "s|name: test-pod|name: test-pod-managed|g" ./deploy/test-pod-managed.yaml
sed -i'' "s|name: nfs-pvc|name: test-nfs-pvc-managed|g" ./deploy/test-pod-managed.yaml
sed -i'' "s|claimName: test-claim|claimName: test-claim-managed|g" ./deploy/test-pod-managed.yaml

oc create -f deploy/test-claim-managed.yaml -f deploy/test-pod-managed.yaml
Verify
oc delete -f deploy/test-claim-managed.yaml -f deploy/test-pod-managed.yaml

69. Set the Default Storage Class to OpenShift Storage - General Use
oc patch storageclass managed-nfs-storage -p '{"metadata": {"annotations": {"storageclass.kubernetes.io/is-default-class": "true"}}}'


#Set the Identity Provider OAuth to Active Directory
1. login to console
2. Click Administration -> Cluster Settings
3. Click OAuth
4. Select LDAP from the drop-down of Identity Providers
5. 


